# BAKE: Behavioral Alignment & Knowledge Extraction

**BAKE** æ˜¯ä¸€å€‹è‡ªå‹•åŒ–çš„æç¤ºè©žå„ªåŒ–ï¼ˆPrompt Optimizationï¼‰æ¡†æž¶ã€‚å®ƒä¸åªæ˜¯å–®ç´”åœ°å°‹æ‰¾ã€Œæ›´å¥½çš„æç¤ºè©žã€ï¼Œè€Œæ˜¯é€éŽåˆ†æžæ¨¡åž‹åœ¨ç‰¹å®šä»»å‹™ä¸Šçš„å¤±æ•—æ¡ˆä¾‹ï¼Œæå–å‡ºæ¨¡åž‹åå¥½çš„è¡Œç‚ºè¦å‰‡ï¼ˆBehavioral Alignmentï¼‰ï¼Œä¸¦å°‡é€™äº›éš±æ€§çŸ¥è­˜è½‰åŒ–ç‚ºé¡¯æ€§çš„æŒ‡å°ŽåŽŸå‰‡ï¼ˆKnowledge Extractionï¼‰ï¼Œæœ€çµ‚ç”Ÿæˆé«˜è³ªé‡çš„é€šç”¨æç¤ºè©žã€‚

æœ¬å°ˆæ¡ˆå¯¦ä½œäº† BAKE çš„æ ¸å¿ƒæµç¨‹ï¼Œä¸¦æ”¯æ´ **è¿­ä»£å¼å„ªåŒ–ï¼ˆIterative Optimizationï¼‰**ï¼Œå…è¨±åœ¨å„ªåŒ–éŽç¨‹ä¸­å‹•æ…‹æ›´æ–°æç¤ºè©žæ± ã€‚

## âœ¨ ä¸»è¦åŠŸèƒ½

  * **é›™æ¨¡åž‹æž¶æ§‹**ï¼š
      * **Scorer (Task Model)**ï¼šè² è²¬åŸ·è¡Œä»»å‹™ä¸¦ç”±ç³»çµ±è©•ä¼°å°éŒ¯ï¼ˆå¦‚ Qwen-7B, GPT-3.5ï¼‰ã€‚
      * **Optimizer (Teacher Model)**ï¼šè² è²¬åˆ†æžéŒ¯èª¤ã€é‡å¯«æç¤ºè©žä¸¦ç¸½çµè¦å‰‡ï¼ˆå¦‚ Qwen-32B, GPT-4ï¼‰ã€‚
  * **è‡ªå‹•åŒ–æµç¨‹**ï¼šåŒ…å«è©•ä¼° (Evaluation)ã€å„ªåŒ– (Refinement)ã€è¦å‰‡æå– (Rule Extraction) èˆ‡åˆä½µ (Merging)ã€‚
  * **è¿­ä»£æ¨¡å¼ (Iterative Mode)**ï¼šæ”¯æ´åœ¨é‹è¡ŒéŽç¨‹ä¸­æ ¹æ“šæ–°ç”Ÿæˆçš„è¦å‰‡å³æ™‚æ›´æ–°æç¤ºè©žæ± ï¼Œå¯¦ç¾ã€Œåœ¨ç·šå­¸ç¿’ã€ã€‚
  * **å¤šæ¨¡åž‹æ”¯æ´**ï¼šé€éŽ `LLMClient` æ”¯æ´ **OpenAI API** èˆ‡ **Ollama** æœ¬åœ°æ¨¡åž‹ã€‚
  * **è©³ç´°æ—¥èªŒ**ï¼šå®Œæ•´è¨˜éŒ„å„ªåŒ–è»Œè·¡ã€æˆæœ¬ä¼°ç®—èˆ‡è¦å‰‡æ¼”è®ŠéŽç¨‹ã€‚

## ðŸ“‚ å°ˆæ¡ˆçµæ§‹

```text
BAKE/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ bake_engine.py      # BAKE æ ¸å¿ƒå¼•æ“Žï¼šè™•ç†è©•ä¼°ã€å„ªåŒ–ã€è¦å‰‡æå–é‚è¼¯
â”‚   â””â”€â”€ llm_client.py       # LLM å®¢æˆ¶ç«¯ï¼šè™•ç† OpenAI/Ollama é€£ç·šèˆ‡è¨ˆè²»
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config_loader.py    # è®€å– YAML è¨­å®šèˆ‡ Meta Prompts
â”‚   â”œâ”€â”€ data_loader.py      # è¼‰å…¥è³‡æ–™é›† (MMLU, GSM8K)
â”‚   â”œâ”€â”€ logger.py           # æ—¥èªŒè¨˜éŒ„å·¥å…· (Thread-safe)
â”‚   â””â”€â”€ text_tools.py       # æ–‡å­—è™•ç†èˆ‡ç­”æ¡ˆé©—è­‰å·¥å…·
â”œâ”€â”€ meta_prompt/            # [é—œéµ] çµ¦ Optimizer ä½¿ç”¨çš„å…ƒæç¤ºè©žæ¨¡æ¿
â”‚   â”œâ”€â”€ analyze_and_rewrite.txt
â”‚   â”œâ”€â”€ combine_rules.txt
â”‚   â”œâ”€â”€ prompt_generation.txt
â”‚   â””â”€â”€ rule_summarization.txt
â”œâ”€â”€ config.yaml             # ä¸»è¦è¨­å®šæª” (æ¨¡åž‹åƒæ•¸ã€è·¯å¾‘ã€è³‡æ–™é›†)
â”œâ”€â”€ main.py                 # ç¨‹å¼é€²å…¥é»ž
â”œâ”€â”€ BAKE.sh                 # æ‰¹æ¬¡å¯¦é©—è‡ªå‹•åŒ–è…³æœ¬
â””â”€â”€ requirements.txt        # Python ä¾è³´å¥—ä»¶
```

## ðŸš€ å®‰è£èˆ‡ç’°å¢ƒè¨­å®š

1.  **Clone å°ˆæ¡ˆ**

    ```bash
    git clone https://github.com/your-repo/BAKE.git
    cd BAKE
    ```

2.  **å®‰è£ä¾è³´å¥—ä»¶**
    å»ºè­°ä½¿ç”¨ Python 3.10+ ç’°å¢ƒï¼š

    ```bash
    pip install -r requirements.txt
    ```

3.  **è¨­å®šæ¨¡åž‹å¾Œç«¯**

      * **æœ¬åœ°æ¨¡åž‹ (Ollama)**ï¼šè«‹ç¢ºä¿ Ollama å·²å•Ÿå‹•ä¸¦ä¸‹è¼‰äº†ç›¸æ‡‰æ¨¡åž‹ï¼ˆå¦‚ `qwen2.5:7b`ï¼‰ã€‚
      * **é›²ç«¯æ¨¡åž‹ (OpenAI)**ï¼šè«‹æº–å‚™å¥½ API Keyã€‚

## âš™ï¸ é…ç½®èªªæ˜Ž (`config.yaml`)

åœ¨åŸ·è¡Œå‰ï¼Œè«‹ç·¨è¼¯ `config.yaml` ä»¥ç¬¦åˆæ‚¨çš„ç’°å¢ƒï¼š

```yaml
# æ¨¡åž‹è¨­å®š
scorer:
  provider: "ollama"       # æˆ– "openai"
  model_name: "qwen2.5:7b" # åŸ·è¡Œä»»å‹™çš„å°æ¨¡åž‹
  base_url: "http://localhost:11434/v1"

optimizer:
  provider: "ollama"       # æˆ– "openai"
  model_name: "qwen2.5:32b" # è² è²¬å„ªåŒ–çš„å¤§æ¨¡åž‹ (å»ºè­°èƒ½åŠ›è¼ƒå¼·è€…)

# è³‡æ–™é›†è¨­å®š
datasets:
  - name: "mmlu"
    subsets: ["high_school_mathematics", "professional_law"] # æŒ‡å®šå­é›†
    limit: 10 # æ¯å€‹å­é›†æ¸¬è©¦å¹¾é¡Œ

# åˆå§‹æç¤ºè©ž
initial_prompts:
  - "Let's think step by step."
  - "Think about this logically."
```

## ðŸƒâ€â™‚ï¸ åŸ·è¡Œæ–¹å¼

### æ–¹å¼ 1ï¼šä½¿ç”¨ Python ç›´æŽ¥åŸ·è¡Œ

æ‚¨å¯ä»¥ç›´æŽ¥åŸ·è¡Œ `main.py` ä¸¦é€éŽåƒæ•¸è¦†è“‹è¨­å®šæª”ï¼š

```bash
python main.py \
  --output_dir experiments/run_01 \
  --scorer_model "qwen2.5:7b" \
  --optimizer_model "gpt-4o" \
  --iterative  # é–‹å•Ÿè¿­ä»£æ¨¡å¼ (é¸å¡«)
```

**åƒæ•¸èªªæ˜Žï¼š**

  * `--output_dir`: è¼¸å‡ºçµæžœèˆ‡ Log çš„è³‡æ–™å¤¾è·¯å¾‘ï¼ˆå¿…å¡«ï¼‰ã€‚
  * `--iterative`: æ˜¯å¦é–‹å•Ÿè¿­ä»£æ¨¡å¼ã€‚è‹¥é–‹å•Ÿï¼Œç³»çµ±æœƒåœ¨ç”Ÿæˆ Tier-1 è¦å‰‡å¾Œç«‹å³ç”¢ç”Ÿæ–°æç¤ºè©žä¸¦ç”¨æ–¼å¾ŒçºŒé¡Œç›®ã€‚
  * `--dataset_limit`: å¼·åˆ¶è¦†è“‹æ¸¬è©¦æ¨£æœ¬æ•¸é‡ã€‚

### æ–¹å¼ 2ï¼šä½¿ç”¨ Shell è…³æœ¬é€²è¡Œæ‰¹æ¬¡å¯¦é©—

å°ˆæ¡ˆæä¾›äº† `BAKE.sh` ä¾†è‡ªå‹•åŒ–åŸ·è¡Œå¤šçµ„å¯¦é©—é…ç½®ï¼š

```bash
chmod +x BAKE.sh
./BAKE.sh
```

æ‚¨å¯ä»¥åœ¨ `BAKE.sh` ä¸­ä¿®æ”¹ `EXPERIMENTS` é™£åˆ—ä¾†å®‰æŽ’å¯¦é©—ä½‡åˆ—ï¼š

```bash
EXPERIMENTS=(
    # Scorer | Optimizer | DatasetLimit | IterativeMode
    "qwen2.5:7b|qwen2.5:32b|100|true"
    "gpt-3.5-turbo|gpt-4|50|false"
)
```

## ðŸ“Š è¼¸å‡ºçµæžœ

åŸ·è¡Œå®Œæˆå¾Œï¼Œçµæžœå°‡ä¿å­˜åœ¨æŒ‡å®šçš„ `--output_dir` ä¸­ï¼š

  * **`optimized_prompts.txt`**ï¼šæœ€çµ‚ç”Ÿæˆçš„å„ªåŒ–æç¤ºè©žåˆ—è¡¨ã€‚
  * **`final_rule.txt`**ï¼šæœ€çµ‚æå–å‡ºçš„é€šç”¨æç¤ºè©žè¨­è¨ˆè¦å‰‡ï¼ˆBehavioral Ruleï¼‰ã€‚
  * **`detailed_results.jsonl`**ï¼šæ¯ä¸€é¡Œçš„è©³ç´°è©•ä¼°çµæžœï¼ˆåŒ…å«æ­£ç¢º/éŒ¯èª¤çš„æç¤ºè©žï¼‰ã€‚
  * **`optimization_status.csv`**ï¼šæ¯ä¸€é¡Œçš„å„ªåŒ–ç‹€æ…‹ï¼ˆæˆåŠŸã€å¤±æ•—ã€è·³éŽï¼‰ã€‚
  * **`rule_evolution.jsonl`**ï¼šè¨˜éŒ„è¦å‰‡å¾žå–®é¡Œå±¬æ€§åˆ°å…¨åŸŸè¦å‰‡çš„æ¼”è®ŠéŽç¨‹ã€‚
  * **`cost_report.csv`**ï¼šToken ä½¿ç”¨é‡èˆ‡é ä¼°æˆæœ¬å ±å‘Šã€‚

## ðŸ› ï¸ é€²éšŽå®¢è£½åŒ–

è‹¥éœ€èª¿æ•´å„ªåŒ–é‚è¼¯ï¼Œè«‹ä¿®æ”¹ `meta_prompt/` ä¸‹çš„æ–‡ä»¶ï¼š

  * `analyze_and_rewrite.txt`: æŒ‡å°Ž Optimizer å¦‚ä½•è¨ºæ–·éŒ¯èª¤ä¸¦é‡å¯«æç¤ºè©žã€‚
  * `combine_rules.txt`: æŒ‡å°Ž Optimizer å¦‚ä½•åˆä½µå¤šæ¢è¦å‰‡ã€‚
  * `prompt_generation.txt`: æŒ‡å°Ž Optimizer å¦‚ä½•æ ¹æ“šè¦å‰‡ç”Ÿæˆæ–°æç¤ºè©žã€‚

## ðŸ“œ å¼•ç”¨èˆ‡åƒè€ƒ

æœ¬ä»£ç¢¼åŸºæ–¼ BAKE è«–æ–‡æ¦‚å¿µå¯¦ä½œã€‚æ ¸å¿ƒé‚è¼¯åƒè€ƒè‡ªï¼š

> *BAKE: Behavioral Alignment & Knowledge Extraction for Prompt Optimization*

-----

**License**: MIT
**Author**: Emily