# ----------------------------------------------------
# 專案設定
# ----------------------------------------------------
project:
  log_dir: './logs'

# ----------------------------------------------------
# 資料集設定 (New!)
# ----------------------------------------------------
dataset:
  name: 'mmlu'               # 選項: 'mmlu', 'gsm8k'
  split: 'test'              # mmlu 通常用 'test', gsm8k 常用 'train'
  data_root: './data'
  
  # [MMLU 專用] 指定子集。若為 'all' 則載入全部，或列表指定特定子集
  subsets: 
    - 'high_school_mathematics'
    - 'high_school_physics'
    # - 'all' 
  
  # [關鍵設定] 訓練集筆數限制。設為整數 (如 50) 或 'all' (全部)
  # 這會決定從載入的資料中取出多少筆作為 OPRO 的優化訓練集
  train_limit: 20

# ----------------------------------------------------
# Scorer Model
# ----------------------------------------------------
scorer_model:
  client_type: 'Ollama'
  model_name: 'qwen2.5:7b'
  api_url: 'http://localhost:11434/api/chat'
  temperature: 0.0
  max_output_tokens: 1024

# ----------------------------------------------------
# Optimizer Model
# ----------------------------------------------------
optimizer_model:
  client_type: 'Ollama'
  model_name: 'qwen2.5:32b'
  api_url: 'http://localhost:11434/api/chat'
  temperature: 0.7
  max_output_tokens: 2048

# ----------------------------------------------------
# OPRO 優化參數
# ----------------------------------------------------
optimization:
  train_ratio: 0.8
  eval_interval: 3  ## 每幾步執行一次驗證集檢查
  num_iterations: 3           # 測試時建議先設小一點 (例如 20)
  num_prompts_to_generate: 8
  max_num_instructions_in_prompt: 20
  
  # [修正] 路徑改為 prompt (單數) 以匹配您的資料夾結構
  meta_prompt_path: 'prompt/meta_prompt.txt'
  
  # [新增] 支援 Scorer 的格式調整
  instruction_pos: 'Q_begin'
  is_instruction_tuned: true
  
  # [新增] 支援 Optimizer 的錯誤驅動策略
  num_few_shot_questions: 3
  few_shot_selection_criteria: 'random'
  old_instruction_score_threshold: 0.1

  initial_instructions:
    - "Let's think step by step."
    - "Solve this problem carefully."
    - "Provide a detailed answer."
    - "Answer the question directly."