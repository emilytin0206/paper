import os
import sys
import json
import glob
import logging
import argparse
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from src.client import OllamaClient
from src.loader import MMLUDataLoader
from src.scorer import Scorer

# è¨­å®š Log
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("Main")

def main():
    parser = argparse.ArgumentParser(description="Automated Prompt Evaluation System")
    parser.add_argument("--model", type=str, default="llama3", help="Ollama model name")
    parser.add_argument("--subsets", type=str, default="global_facts", help="Comma separated MMLU subsets")
    parser.add_argument("--split", type=str, default="validation", help="Dataset split")
    parser.add_argument("--prompt_dir", type=str, default="./prompts", help="Directory containing prompt JSONs")
    parser.add_argument("--output_dir", type=str, default="./results", help="Directory to save results")
    parser.add_argument("--limit", type=int, default=5, help="Num samples per prompt (use 0 for all)")
    
    args = parser.parse_args()
    
    # 1. æº–å‚™å…ƒä»¶
    client = OllamaClient(model_name=args.model)
    subsets_list = [s.strip() for s in args.subsets.split(',')]
    loader = MMLUDataLoader(subsets=subsets_list, split=args.split)
    scorer = Scorer(client, config_mode='Q_begin')

    # 2. è¼‰å…¥è³‡æ–™
    logger.info("Loading Dataset...")
    dataset = loader.load_data()
    
    # 3. ç¢ºä¿ç›®éŒ„å­˜åœ¨
    os.makedirs(args.output_dir, exist_ok=True)
    
    # 4. æƒææª”æ¡ˆä¸¦åŸ·è¡Œ
    json_files = glob.glob(os.path.join(args.prompt_dir, "*.json"))
    
    # --- ä¿®æ”¹é€™è£¡ï¼šæ›´æ˜ç¢ºçš„ Limit åˆ¤æ–·èˆ‡ Log æç¤º ---
    if args.limit > 0:
        num_samples = args.limit
        logger.info(f"ğŸ”§ Config: Sampling first {num_samples} items per prompt.")
    else:
        num_samples = None
        logger.info("ğŸ”§ Config: Limit set to 0. Running on FULL dataset (All samples).")

    for json_file in json_files:
        full_file_name = os.path.basename(json_file)
        base_name = os.path.splitext(full_file_name)[0]
        
        logger.info(f"Processing: {full_file_name}")
        
        with open(json_file, 'r') as f:
            data = json.load(f)
        
        results = []
        prompts = data.get("prompts", [])
        
        for idx, item in enumerate(prompts):
            # å…¼å®¹è™•ç†ï¼šç„¡è«–è¼¸å…¥æ˜¯å­—ä¸²é‚„æ˜¯ç‰©ä»¶ï¼Œéƒ½å–å‡º Prompt æ–‡å­—
            p_text = item if isinstance(item, str) else item.get("text", "")
            
            # é›–ç„¶è¼¸å‡ºä¸å­˜ IDï¼Œä½† Log é‚„æ˜¯å°ä¸€ä¸‹æ–¹ä¾¿ä½ çœ‹é€²åº¦
            p_id_log = f"p_{idx}" if isinstance(item, str) else item.get("id", f"p_{idx}")
            
            if not p_text: continue
            
            logger.info(f"Testing: {p_id_log}")
            res = scorer.score_instruction(p_text, dataset, num_samples=num_samples)
            
            # ==========================================
            # ä¿®æ”¹é‡é»ï¼šåªå„²å­˜ score å’Œ prompt
            # ==========================================
            results.append({
                "score": res['score'],
                "prompt": p_text,
                "count": res['num_evals']  # <--- åŠ å…¥é€™è¡Œï¼Œæ–¹ä¾¿æ‚¨ç¢ºèªæ˜¯å¦çœŸçš„è·‘äº† 300 é¡Œ
            })
            
            logger.info(f"Score: {res['score']:.2%}")

        # è¼¸å‡ºçµæœæª”æ¡ˆ
        out_filename = f"{base_name}_result.json"
        out_path = os.path.join(args.output_dir, out_filename)
        
        # é€™è£¡æˆ‘ä¿ç•™äº†å¤–å±¤çš„ metadata (source_file ç­‰)ï¼Œè®“æª”æ¡ˆçµæ§‹æ˜¯åˆæ³•çš„ JSON
        # å¦‚æœä½ é€£å¤–å±¤éƒ½ä¸è¦ï¼Œåªæƒ³å­˜ results listï¼Œå¯ä»¥æ”¹ç‚º json.dump(results, f, ...)
        with open(out_path, 'w', encoding='utf-8') as f:
            json.dump({
                "source_file": full_file_name,
                "model": args.model,
                "subsets": subsets_list,
                "results": results  # é€™è£¡é¢ç¾åœ¨åªæœ‰ score å’Œ prompt
            }, f, indent=2, ensure_ascii=False)
            
        logger.info(f"Saved results to: {out_filename}")

if __name__ == "__main__":
    main()